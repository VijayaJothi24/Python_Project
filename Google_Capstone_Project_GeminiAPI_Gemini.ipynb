{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "name": "Google_Capstone_Project_GeminiAPI_Gemini",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayaJothi24/Python_Project/blob/main/Google_Capstone_Project_GeminiAPI_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiModal AI Capablity *Image,Text,Video,Audio * understanding with Gemini"
      ],
      "metadata": {
        "id": "WMGdicu8PVD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image understanding with Gemini"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-13T11:06:42.216104Z",
          "iopub.execute_input": "2025-04-13T11:06:42.216407Z",
          "iopub.status.idle": "2025-04-13T11:06:42.220472Z",
          "shell.execute_reply.started": "2025-04-13T11:06:42.216385Z",
          "shell.execute_reply": "2025-04-13T11:06:42.219642Z"
        },
        "id": "H8ZdG5l7FebW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini has from the begining been a multimodal model, capable of analyzing all sorts of medias using its [long context window](https://developers.googleblog.com/en/new-features-for-the-gemini-api-and-google-ai-studio/).\n",
        "\n",
        "[Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2) and later bring Image analysis to a whole new level as illustrated in [this image](https://i.pinimg.com/474x/c2/f7/52/c2f75236a0882c1e3dae641ae0fe6769.jpg):\n"
      ],
      "metadata": {
        "id": "3w14yjWnPVD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display the image from the URL\n",
        "image_url = \"https://i.pinimg.com/736x/fd/95/02/fd95021c676932304e41167ce9d86211.jpg\"\n",
        "display(Image(url=image_url))\n",
        "\n"
      ],
      "metadata": {
        "id": "CumMaR-sts53",
        "outputId": "66e4c5d6-2a09-4b54-f4a7-f58094a37557",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-13T11:08:45.989Z",
          "iopub.execute_input": "2025-04-13T11:08:45.989344Z",
          "iopub.status.idle": "2025-04-13T11:08:45.994918Z",
          "shell.execute_reply.started": "2025-04-13T11:08:45.98932Z",
          "shell.execute_reply": "2025-04-13T11:08:45.994282Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://i.pinimg.com/736x/fd/95/02/fd95021c676932304e41167ce9d86211.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will show you how to easily use Gemini to perform the same kind of image, video and text analysis. Each of them has different prompts that you can select using the dropdown, also feel free to experiment with your own.\n",
        "\n",
        "."
      ],
      "metadata": {
        "id": "jexx9acnuDsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "This section install the SDK, set it up using  [API key](../quickstarts/Authentication.ipynb), imports the relevant libs, downloads the sample videos and upload them to Gemini.\n"
      ],
      "metadata": {
        "id": "R0HWzIEAQYqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install SDK\n",
        "\n",
        "The new **[Google Gen AI SDK](https://ai.google.dev/gemini-api/docs/sdks)** provides programmatic access to Gemini 2.0 (and previous models) using both the [Google AI for Developers](https://ai.google.dev/gemini-api/docs) and [Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview) APIs. With a few exceptions, code that runs on one platform will run on both."
      ],
      "metadata": {
        "id": "UzBKAaL4QYq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q 'google-genai'"
      ],
      "metadata": {
        "id": "IbKkL5ksQYq1",
        "outputId": "38850ae2-c54b-400b-f14b-2f894282f708",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/154.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/154.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`."
      ],
      "metadata": {
        "id": "aDUGen_kQYq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "0H_lRdlrQYq3"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize SDK client\n",
        "\n",
        "With the new SDK only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call."
      ],
      "metadata": {
        "id": "_3Lez1vBQYq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "X3CAp9YrQYq4"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select the Gemini model\n",
        "\n",
        "Video understanding works best Gemini 2.5 pro model. Also select former models to compare their behavior but it is recommended to use at least the 2.0 ones.\n",
        "\n"
      ],
      "metadata": {
        "id": "ITgsQyaXQYq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gemini-2.5-pro-exp-03-25\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}"
      ],
      "metadata": {
        "id": "IO7IoqbrQYq5"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get sample iMAGEs\n",
        "\n",
        "I will start with uploaded image, as it's a more common use-case, but I will also see later to analyse Youtube videos."
      ],
      "metadata": {
        "id": "rv8ULT0lvJ47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Function to download and process image from URL\n",
        "def process_image_from_url(url):\n",
        "    try:\n",
        "        # Fetch the image data from the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise error for bad response\n",
        "        image_data = BytesIO(response.content)\n",
        "\n",
        "        # Open the image using Pillow\n",
        "        image = Image.open(image_data)\n",
        "\n",
        "        # Example: Convert image to grayscale\n",
        "        grayscale_image = image.convert(\"L\")\n",
        "        grayscale_image.show()  # Display the processed image\n",
        "\n",
        "        # Save the processed image locally\n",
        "        grayscale_image.save(\"processed_image.jpg\")\n",
        "        print(\"Image processed and saved as 'processed_image.jpg'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "\n",
        "# Replace with your URL\n",
        "image_url = \"https://i.pinimg.com/736x/fd/95/02/fd95021c676932304e41167ce9d86211.jpg\"\n",
        "process_image_from_url(image_url)\n"
      ],
      "metadata": {
        "id": "vDq7Gcbrfm2U",
        "outputId": "160f716d-1672-42e6-e3c6-f5f425dc2b92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image processed and saved as 'processed_image.jpg'\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(file=video_file_name)\n",
        "\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'image processing complete: ' + video_file.uri)\n",
        "\n",
        "  return video_file\n",
        "\n",
        "Image_analyse = upload_video('processed_image.jpg')\n"
      ],
      "metadata": {
        "id": "abZyD0ofg9kl",
        "outputId": "bb66a17e-b6d7-4785-cbb4-30b79853dee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image processing complete: https://generativelanguage.googleapis.com/v1beta/files/2m5fd6q7zh99\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the image\n",
        "\n",
        "Upload  the image using the File API.\n",
        "\n",
        "This can take a couple of minutes as the videos will need to be processed and tokenized."
      ],
      "metadata": {
        "id": "Y4YMNQulz_yY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "IF5tDbb-Q0oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import display, Markdown, HTML"
      ],
      "metadata": {
        "id": "B0Z9QzC3Q2wX"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display the image\n",
        "image_url = \"https://i.pinimg.com/736x/fd/95/02/fd95021c676932304e41167ce9d86211.jpg\"\n",
        "display(Image(url=image_url))\n"
      ],
      "metadata": {
        "id": "Cth2dDOJnMOd",
        "outputId": "c4e08144-da78-43b3-ae38-77a863ab3c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://i.pinimg.com/736x/fd/95/02/fd95021c676932304e41167ce9d86211.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Describe the image in detail, focusing on the key objects, characters, and their interactions. Identify any notable patterns, colors, or themes present in the scene. Highlight the context or purpose of the elements within the image, and interpret the overall mood or message conveyed. Include any symbolic or cultural significance if applicable.\"\n",
        "\n",
        "video = \"processed_image.jpg\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=[\n",
        "        video,\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)\n"
      ],
      "metadata": {
        "id": "PZw41-lsKKMf",
        "outputId": "1ea17619-c1fd-4965-ba98-1bc28c8fc741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, let's break down the provided image, \"processed_image.jpg\".\n\n**Overall Impression:**\nThe image is a clean, modern digital graphic, likely serving as promotional or informational material for a technology product or service called \"Gemini\". It features a friendly robot mascot as the central figure, surrounded by icons representing various capabilities.\n\n**Key Objects and Characters:**\n\n1.  **Central Character (Robot/Mascot):**\n    *   **Appearance:** A stylized, anthropomorphic robot dominates the center. It's primarily white and various shades of blue. The head is large and round with a screen-like face displaying simple, friendly blue line-art eyes. Two blue antennae with white tips protrude from the top. The torso is white with blue accents. The arms and legs are blue, segmented or cylindrical, ending in simple white mitten-like hands and rounded blue feet.\n    *   **Pose:** The robot stands facing slightly towards the viewer, with its left arm slightly raised and palm open in a welcoming or presenting gesture. Its head is slightly tilted, enhancing its friendly demeanor.\n    *   **Interaction:** The robot acts as the embodiment or representative of \"Gemini\". Its friendly design aims to make the associated technology seem approachable and helpful.\n\n2.  **Text \"Gemini\":**\n    *   **Appearance:** The word \"Gemini\" is written in a large, bold, modern sans-serif font.\n    *   **Placement:** Positioned prominently, usually below or near the robot, clearly identifying the subject of the graphic.\n    *   **Color:** Typically rendered in blue, matching the robot's color scheme.\n    *   **Purpose:** This is the brand name or product name being presented.\n\n3.  **Capability Icons:**\n    *   **Appearance:** Several circular icons are arranged around the central robot, often appearing to orbit or emanate from it. Each icon contains a simple, stylized graphic symbol within the circle and often has a text label below it.\n    *   **Content:** These icons represent the functions or capabilities associated with Gemini. Common examples seen in such graphics might include:\n        *   A speech bubble (for chat/conversation)\n        *   A pen or document (for writing/drafting)\n        *   A lightbulb (for ideas/brainstorming)\n        *   Code brackets `</>` (for coding/programming assistance)\n        *   An artist's palette (for creative tasks/design)\n    *   **Purpose:** To quickly convey the versatility and range of tasks that Gemini can assist with.\n\n4.  **Background:**\n    *   **Appearance:** The background is typically minimalistic, often featuring a smooth gradient transitioning between shades of blue, purple, or white. It might include subtle abstract shapes, light flares, or soft geometric patterns to add depth without distracting from the main elements.\n    *   **Purpose:** To provide a clean, visually appealing, and modern backdrop that reinforces the technological theme.\n\n**Patterns, Colors, and Themes:**\n\n*   **Patterns:** Repetition of circular shapes (icons), clean lines, smooth curves in the robot design, and often a gradient pattern in the background.\n*   **Colors:** Dominated by blues and white. Blue evokes technology, trust, intelligence, and stability. White suggests simplicity, cleanliness, and modernity. Occasional accents of other colors (like purple in gradients) might add visual interest.\n*   **Themes:**\n    *   **Technology & AI:** Clearly central, represented by the robot and functional icons.\n    *   **Helpfulness & Assistance:** The friendly mascot and task-oriented icons suggest a tool designed to aid users.\n    *   **Versatility & Creativity:** The range of icons (coding, writing, ideas) highlights broad applicability.\n    *   **Modernity & Simplicity:** The overall design aesthetic is clean, uncluttered, and contemporary.\n\n**Context and Purpose:**\n\n*   **Context:** This graphic is almost certainly related to Google's AI model, Gemini. It's designed for digital platforms (websites, apps, presentations) to introduce or explain what Gemini is and what it can do.\n*   **Purpose:** To create brand recognition for Gemini, communicate its core functionalities in an easily digestible visual format, and establish a friendly, accessible identity for a potentially complex technology (AI).\n\n**Mood and Message:**\n\n*   **Mood:** Optimistic, friendly, helpful, approachable, innovative, and efficient.\n*   **Message:** The core message is that \"Gemini is a powerful yet friendly AI assistant capable of helping you with a wide range of creative, communicative, and technical tasks.\" It emphasizes ease of use and broad utility.\n\n**Symbolic or Cultural Significance:**\n\n*   **Friendly Robot:** Anthropomorphizing AI into a non-threatening, cute robot is a common strategy to make advanced technology less intimidating and more relatable to a broad audience.\n*   **Color Palette:** The use of blue aligns with common cultural associations of the color with technology and trustworthiness (e.g., IBM, Facebook, Twitter).\n*   **Icons:** Using universally recognized symbols for tasks (chat, write, code) transcends language barriers and makes the capabilities instantly understandable.\n\nIn summary, the image is a well-designed piece of branding and informational graphic for the AI \"Gemini,\" using a friendly robot mascot, clear icons, and a clean, modern aesthetic to convey its helpfulness, versatility, and approachable nature."
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract and organize text\n",
        "\n",
        "Gemini can also read what's in the .csv file and extract it in an organized way. Gemini reasoning capabilities can generate new ideas for you.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wog32E7CKnT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_csv_from_url(url):\n",
        "    try:\n",
        "        # Fetch the CSV data from the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error for unsuccessful requests\n",
        "\n",
        "        # Save the CSV content locally (optional)\n",
        "        with open(\"downloaded_file.csv\", \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "\n",
        "        # Load the CSV into a Pandas DataFrame\n",
        "        df = pd.read_csv(\"downloaded_file.csv\")\n",
        "\n",
        "        # Example Analysis: Display basic information about the data\n",
        "        print(\"First 5 rows:\")\n",
        "        print(df.head())\n",
        "\n",
        "        print(\"\\nSummary Statistics:\")\n",
        "        print(df.describe())\n",
        "\n",
        "        print(\"\\nColumns in the CSV file:\")\n",
        "        print(df.columns)\n",
        "\n",
        "        # You can add further analysis depending on your requirements\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "\n",
        "\n",
        "# Replace with your CSV URL\n",
        "csv_url = \"https://raw.githubusercontent.com/VijayaJothi24/VijayaJothi24/main/City.csv\"\n",
        "\n",
        "analyze_csv_from_url(csv_url)\n"
      ],
      "metadata": {
        "id": "baNCeA3GKrfu",
        "outputId": "32376a98-bfd5-4315-e5e0-8bb89588c5b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows:\n",
            "               City Population    Users\n",
            "0       NEW YORK NY  8,405,837  302,149\n",
            "1  SAN FRANCISCO CA    629,591  213,609\n",
            "2        CHICAGO IL  1,955,130  164,468\n",
            "3    LOS ANGELES CA  1,595,037  144,132\n",
            "4     WASHINGTON DC    418,859  127,001\n",
            "\n",
            "Summary Statistics:\n",
            "               City Population    Users\n",
            "count            20         20       20\n",
            "unique           20         20       20\n",
            "top     NEW YORK NY  8,405,837  302,149\n",
            "freq              1          1        1\n",
            "\n",
            "Columns in the CSV file:\n",
            "Index(['City', 'Population', 'Users'], dtype='object')\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, Gemini is able to grasp to with item corresponds each note, including the last one."
      ],
      "metadata": {
        "id": "Zsh6i-Z6VHNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze youtube videos\n",
        "\n",
        "Downbelow Another Generative AI capablity task of Video Analysing is done"
      ],
      "metadata": {
        "id": "TEYYemjyKcZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=model_name,\n",
        "    contents=types.Content(\n",
        "        parts=[\n",
        "            types.Part(text=\"Find all the instances where Vijaya says \\\"software testing\\\". Provide timestamps and broader context for each instance.\"),\n",
        "            types.Part(\n",
        "                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=13TBF_4KqXA')\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "Markdown(response.text)\n"
      ],
      "metadata": {
        "id": "DP0Dd0hJKvYm",
        "outputId": "d6ca1ccf-495e-4a9d-c83e-1b7ec6e8eb58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, here are the instances where Vijaya says \"software testing\", along with timestamps and context:\n\n1.  **Timestamp:** 0:06 - 0:07\n    *   **Context:** Vijaya is introducing the mind map displayed on the screen. She states, \"So, this is the screen for the **software testing** foundation tidbits.\" She is identifying the central topic of the mind map.\n\n2.  **Timestamp:** 1:10 - 1:11\n    *   **Context:** Vijaya is defining the term 'Defect' as shown on the mind map branch. She says, \"So defect is an error identified in **software testing**.\" She is providing the definition associated with the 'Defect' node.\n\n3.  **Timestamp:** 1:32 - 1:33\n    *   **Context:** While explaining the 'Root Cause' example related to a defect in a fitness tracker application, Vijaya mentions how such an issue would be discovered. She says, \"...it is found during a **software testing**.\" This is part of illustrating a real-world defect scenario.\n\n4.  **Timestamp:** 3:15 - 3:17\n    *   **Context:** Vijaya is discussing the 'Value of Static Testing'. She explains why it's important, stating, \"This states the necessity of static testing in the **software testing** environment.\" She emphasizes its role in finding defects that dynamic testing might miss within the overall testing process."
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "execution_count": 14
    }
  ]
}